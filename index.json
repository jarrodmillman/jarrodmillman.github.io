[{"authors":["admin"],"categories":null,"content":"I am a PhD candidate in biostatistics at UC Berkeley. I received a BA in mathematics and computer science from Cornell University in 1998. After working at the Center for Neuroscience at UC Davis, I came to UC Berkeley in 2000\u0026mdash;first to design the data analysis system for the Brain Imaging Center and then as the director of research computing for the Neuroscience Institute.\nAt Berkeley, I cofounded the Neuroimaging in Python project. I was the NumPy and SciPy release manager from 2007 to 2009. I cofounded NumFOCUS and served on its board from 2011 to 2015. Currently, I am the release manager of NetworkX.\nIn 2015, I began the biostatistics PhD program. I am advised by Prasad Raghavendra and Sandrine Dudoit. My interests include algorithms, scientific computing, and neuroscience.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a PhD candidate in biostatistics at UC Berkeley. I received a BA in mathematics and computer science from Cornell University in 1998. After working at the Center for Neuroscience at UC Davis, I came to UC Berkeley in 2000\u0026mdash;first to design the data analysis system for the Brain Imaging Center and then as the director of research computing for the Neuroscience Institute.\nAt Berkeley, I cofounded the Neuroimaging in Python project.","tags":null,"title":"K. Jarrod Millman","type":"authors"},{"authors":null,"categories":null,"content":"I gave a talk called Python for Statisticians at SciPy India 2015.\n","date":1450051200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1450051200,"objectID":"dfbcb9b171c5d08de84b731b3bce1286","permalink":"/scipyindia2015talk.html","publishdate":"2015-12-14T00:00:00Z","relpermalink":"/scipyindia2015talk.html","section":"post","summary":"I gave a talk called Python for Statisticians at SciPy India 2015.","tags":null,"title":"SciPy India 2015 Talk","type":"post"},{"authors":null,"categories":null,"content":"Prabhu Ramachandran and I gave the introductory tutorial at SciPy India 2015. Here are the slides for session 1, session 2, session 3, and session 4. And here is the pendulum.txt and bird.png files used in the tutorial.\n","date":1450051200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1450051200,"objectID":"79da7dc6c8bbeadf2208f5bca459f62e","permalink":"/scipyindia2015tutorials.html","publishdate":"2015-12-14T00:00:00Z","relpermalink":"/scipyindia2015tutorials.html","section":"post","summary":"Prabhu Ramachandran and I gave the introductory tutorial at SciPy India 2015. Here are the slides for session 1, session 2, session 3, and session 4. And here is the pendulum.txt and bird.png files used in the tutorial.","tags":null,"title":"SciPy India 2015 Tutorials","type":"post"},{"authors":null,"categories":null,"content":"Philip B. Stark, Kellie Ottoboni, Stéfan van der Walt, and I are developing a permutation testing library for Python. The source code is available here. More information about the package is available in my MA thesis.\n","date":1439683200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1439683200,"objectID":"e0ada7622e0a60744c9e93d29f62a90e","permalink":"/ma-thesis.html","publishdate":"2015-08-16T00:00:00Z","relpermalink":"/ma-thesis.html","section":"post","summary":"Philip B. Stark, Kellie Ottoboni, Stéfan van der Walt, and I are developing a permutation testing library for Python. The source code is available here. More information about the package is available in my MA thesis.","tags":null,"title":"permute—a Python package for permutation tests and confidence sets","type":"post"},{"authors":null,"categories":null,"content":" A minisymposium held during the SIAM Conference on Computational Science \u0026amp; Engineering in Salt Lake City, UT on Sunday, March 15, 2015.\nMS78 Summary As dependence on computational tools increases, so does the need for better computational training. We discuss our own efforts to provide such training. We address several larger questions including: What is the role of computational training in our various fields? How can we scale training to meet demand? What technologies, languages, principles, and practices should we teach? What is the right balance between conceptual learning and hands-on training and practice? More generally, how should we train the next generation of scientists, statisticians, and engineers in computational methods and practices?\nTeaching statistical computing to undergraduates (slides)  K. Jarrod Millman (co-organizer) Division of Biostatistics, UC Berkeley Philip B. Stark (co-organizer) Department of Statistics, UC Berkeley  We frame the minisymposium in the context of our experience teaching computing with data to undergraduates. We discuss our recent efforts to automate grading student computational work in Python and R. Automating grading can improve pedagogy by making it easier to assign students more work, reducing latency in providing feedback, and enabling TAs to spend more time working directly with students by freeing them from the \u0026ldquo;busy work\u0026rdquo; of grading.\nTeaching with Version Control (slides)  Randall J. LeVeque Applied Mathematics Department University of Washington  The use of version control is widely viewed as a best practice in the development of software, not only for large scale projects with many collaborators but also for the solo development of research codes. However, students are rarely taught to use version control in courses. I will describe some recent attempts to introduce it into the computational curriculum by requiring students to access course materials, submit homework, and collaborate on group projects via GitHub or BitBucket repositories.\nTeaching Computing to Engineers (slides)  Lorena A. Barba Mechanical \u0026 Aerospace Engineering, The George Washington University  The term \u0026ldquo;computational thinking\u0026rdquo; became quite popular some years ago with a viewpoint piece at the CACM by Wang (2006), but the term goes back to Papert 10 years before. Wang explained it as the ability to think algorithmically and apply problem-solving computation in other fields. We\u0026rsquo;ve been talking about teaching computational thinking ever since. With an interest in reforming how we teach computing to engineering students, I stumbled onto an extension of this idea that defines the pedagogical value of computation. With modern tools for interactive computing (e.g. IPython Notebooks), it becomes possible to learn by computing, to actually create knowledge\u0026mdash;similar to what we do in scientific computing to make discoveries, but in education. I will describe how this thinking has been inspiring several educational initiatives aiming at making computing a core pedagogical instrument.\nCommunity discussion  Notes from community discussion  ","date":1427673600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1427673600,"objectID":"79f67bb42de250210773ef85533ce9da","permalink":"/siam2015.html","publishdate":"2015-03-30T00:00:00Z","relpermalink":"/siam2015.html","section":"post","summary":"A minisymposium held during the SIAM Conference on Computational Science \u0026amp; Engineering in Salt Lake City, UT on Sunday, March 15, 2015.\nMS78 Summary As dependence on computational tools increases, so does the need for better computational training. We discuss our own efforts to provide such training. We address several larger questions including: What is the role of computational training in our various fields? How can we scale training to meet demand?","tags":null,"title":"Teaching computational thinking and practice","type":"post"},{"authors":null,"categories":null,"content":"Fernando Pérez and my chapter titled \u0026ldquo;Developing open source scientific practice\u0026rdquo; was just published in \u0026ldquo;Implementing Reproducible Research (Chapman \u0026amp; Hall/CRC The R Series)\u0026rdquo; edited by Victoria Stodden, Friedrich Leisch, and Roger D. Peng. You can find a preprint on the Open Science Framework (OSF) website along with the other chapters. The source for the chapter will be updated on GitHub.\n","date":1397433600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1397433600,"objectID":"5f857b99fe4896fffdbd64eacaaad977","permalink":"/oss-chapter.html","publishdate":"2014-04-14T00:00:00Z","relpermalink":"/oss-chapter.html","section":"post","summary":"Fernando Pérez and my chapter titled \u0026ldquo;Developing open source scientific practice\u0026rdquo; was just published in \u0026ldquo;Implementing Reproducible Research (Chapman \u0026amp; Hall/CRC The R Series)\u0026rdquo; edited by Victoria Stodden, Friedrich Leisch, and Roger D. Peng. You can find a preprint on the Open Science Framework (OSF) website along with the other chapters. The source for the chapter will be updated on GitHub.","tags":null,"title":"Developing open source scientific practice","type":"post"},{"authors":null,"categories":null,"content":" A mini-symposium at the SIAM Conference on Computational Science \u0026amp; Engineering in Boston, MA on February 28, 2013.\nSummary Since Jon Claerbout adopted and started promoting reproducible research practices much has changed. While the problems for reproducibility of computational results have grown in conjunction with increases in computing power and storage densities, there has also been a steady growth in awareness of these problems and strategies to address them. In this minisymposium, we will discuss several recent attempts to come to terms with reproducibility in computational research. Topics will include education, publication, forensics and scientific integrity, as well as new technologies for provenance tracking and literate programming.\nMS205 - Part I of II Introduction (slides) and ICERM report (slides)\n K. Jarrod Millman, University of California, Berkeley, USA Vincent J. Carey Harvard University, USA  Reproducible Research on the Web: From Homework, Blogging to Open Journals (slides)\n Yihui Xie, Iowa State University, USA  Reproducible research used to be tied to $\\LaTeX{}$ (e.g. Sweave in R) for statisticians, which has a steep learning curve and lacks many features of the web. The underlying idea of literate programming, however, is language agnostic. In this talk, we introduce the R package knitr as a general-purpose tool for reproducible research, with an emphasis on dynamic report generation on the web with Markdown, including reproducible homework, blog posts and online journals in statistics.\nRethinking How we Work with Documents\n Duncan W. Temple Lang, University of California, Davis, USA  Reproducible research tools require capturing all of the different avenues and lines of exploration in research. The document should be a database that can be rendered in different ways for different audiences, allowing dynamic results replacing code, enabling reader interactivity to explore different approaches and what-ifs. We also want to be able to programmatically query, update and verify this document database. All of this leads us to a different structure and approach for authoring documents.\nReproducible Research in Graduate Education in the Computational Sciences\n Sorin Mitran, University of North Carolina at Chapel Hill, USA  Instilling good habits of reproducible computational research can be woven throughout graduate student education. Current software tools allow drafting of live documents that contain theoretical derivations, generation of computational code, verifiable execution of code, and preparation of reports. The talk presents experience in this approach in graduate courses at UNC.\nMS224 - Part II of II Publishing Reproducible Research: Thoughts on Journal Policy\n Roger Peng, Johns Hopkins Bloomberg School of Public Health  I will also discuss the role that journals can play in encouraging reproducible research and will review the recent reproducibility policy at the journal Biostatistics.\nDisseminating Reproducible Computational Research: Tools, Innovations, and Best Practices (slides)\n Victoria Stodden, Columbia University, USA  Computation is now widely recognized as central to the scientific enterprise, and numerous efforts are emerging to incorporate code and data sharing into standards of research dissemination. This goal is challenging from a number of perspectives, including effective research practices. In this talk I discuss novel innovations and best practices for facilitating code and data sharing, both at the time of publication and during the research itself, that support the underlying rational of reproducible research.\nA Portrait of One Scientist as a Graduate Student\n Paul Ivanov, Redwood Center for Theoretical Neuroscience, University of California, Berkeley (slides)  In this talk, I will focus on the how of reproducible research. I will focus on specific tools and techniques I have found invaluable in doing research in a reproducible manner. In particular, I will cover the following general topics (with specific examples in parentheses): version controland code provenance (git), code verification (test driven development, nosetests), data integrity (sha1, md5, git-annex), seed saving ( random seed retention ) distribution of datasets (mirroring, git-annex, metalinks), light-weight analysis capture ( ttyrec, ipython notebook)\nReproducible Research and Omics: Thoughts from the IOM Review\n Keith A. Baggerly, Department of Bioinformatics and Computational Biology, UT MD Anderson Cancer Center (slides)  Between 2007 and 2010, several genomic \u0026ldquo;signatures\u0026rdquo; were used to guide patient therapy in clinical trials in cancer. Unfortunately, the signatures were wrong, and trials proceeded despite warnings to this effect. The Institute of Medicine (IOM) subsequently reviewed the level of evidence that should be required in such situations. Many recommendations focus on reproducibility and data integrity, including directives to funders, journals, and regulatory agencies. We briefly review the report and implications for reproducible research.\n","date":1362009600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1362009600,"objectID":"f4aa7b28945c87320e8c02f79e0e17db","permalink":"/siam2013.html","publishdate":"2013-02-28T00:00:00Z","relpermalink":"/siam2013.html","section":"post","summary":"A mini-symposium at the SIAM Conference on Computational Science \u0026amp; Engineering in Boston, MA on February 28, 2013.\nSummary Since Jon Claerbout adopted and started promoting reproducible research practices much has changed. While the problems for reproducibility of computational results have grown in conjunction with increases in computing power and storage densities, there has also been a steady growth in awareness of these problems and strategies to address them. In this minisymposium, we will discuss several recent attempts to come to terms with reproducibility in computational research.","tags":null,"title":"Reproducibility and computationally intensive, data-driven research","type":"post"},{"authors":null,"categories":null,"content":" A mini-symposium at the SIAM Conference on Computational Science \u0026amp; Engineering in Reno, NV on March 4, 2011.\nSummary As research grows increasingly dependent on computing, it becomes critical for our computational resources to be developed with the same rigor, open review and access as the results they support. In this minisymposium, we will discuss:\n sharing of scientific software, data and knowledge necessary for reproducible research unrestricted access to research outcomes and educational tools open source software developed by collaborative, meritocratic communities openly tested, validated and documented software as the basis for reliable scientific outcomes high standards of computational literacy in the education of mathematicians, scientists and engineers  MS148 - Part I of II The Challenge of Reproducible Research in the Computer Age (slides)\nK. Jarrod Millman, University of California, Berkeley, USA\nComputing is increasingly central to the practice of mathematical and scientific research. This has provided many new opportunities as well as new challenges. In particular, modern scientific computing has strained the ability of researchers to reproduce their own (as well as their colleagues\u0026rsquo;) work. In this talk, I will outline some of the obstacles to reproducible research as well as some potential solutions and opportunities.\nReproducible Research, Lessons from the Madagascar Project (slides)\nSergey Fomel, University of Texas at Austin, USA\nThe Madagascar open-source project is a community effort, which implements reproducible research practices, as envisioned by Jon Claerbout. More than 100 geophysical papers have been published, together with open software code and data, and are maintained by the community. We have learned that continuous maintenance and repeated testing are necessary for enabling long-term reproducibility. As noted by Claerbout and others, the main beneficiary of the reproducible research discipline is the author.\nTop 10 Reasons to NOT Share your Code and Why you Should Anyway (slides)\nRandall J. LeVeque, University of Washington, USA\nThe research codes used to produce results (tables, plots, etc.) in publications are rarely made available, limiting the readers\u0026rsquo; ability to understand the algorithms that are actually implemented. Many objections are typically raised to doing so. Although there are some valid concerns, my view is that there are good counter-arguments or ways to address most of these issues. In this talk I will discuss what may be the top 10 reasons.\nIntellectual Contributions to Digitized Science: Implementing the Scientific Method (slides)\nVictoria Stodden, Columbia University, USA\nOur stock of scientific knowledge is now accumulating in digital form, and the underlying reasoning is often in the code that generated the findings, which is often never published. The case for open data is being made but open code must be recognized as equally important in a principled approach, that of reproducibility of computational results. Issues involved with code and data disclosure are presented, along with possible solutions.\nMS155 - Part II of II Reproducible Research: Lessons from the Open Source World (slides)\nFernando Pérez, University of California, Berkeley, USA\nWhy are the practices of open source software development often more consistent with our ideas of openness and reproducibility in science than science itself? Today\u0026rsquo;s scientific praxis falls short of our ideals of reproducibility, and these problems are particularly acute in computational domains where they should be less prevalent. I will explore the reasons for this and will draw some ideas from software development that provide technical means to address some of these issues.\nFEMhub, a Free Distribution of Open Source Finite Element Codes (slides)\nPavel Solin, Ondrej Certik, Aayush Poudel, and Sameer Regmi, University of Nevada, Reno, USA; Mateusz Paprock, Technical University of Wroclaw, Poland\nFEMhub is an open source distribution of finite element codes with a unified Python interface. The goal of the project is to reduce heterogeneity in installation and usage of open source finite element codes, facilitate their interoperability and comparisons, and improve reproducibility of results. FEMhub is available for download as desktop application, but all codes are also automatically available in the Online Numerical Methods Laboratory.\nReproducible Models and Reliable Simulations: Current Trends in Computational Neuroscience (slides)\nHans E. Plesser, Norwegian University of Life Sciences, Norway; Sharon M. Crook, Arizona State University, USA; Andrew P. Davison, CNRS, France\nComputational neuroscientists simulate models of neuronal networks to further our understanding of brain dynamics. Unfortunately, the validity of models of neuronal dynamics and of the simulation software implementing the models is difficult to ascertain, challenging the validity of computational neuroscience. I will describe how the computational neuroscience community is addressing validity through software reviews, best practices, increasing use of established software packages, meta-simulators, systematic testing, and simulator-independent model-specification languages.\nPublishing Reproducible Results with VisTrails (slides)\nJuliana Freire and Claudio Silva, University of Utah, USA\nVisTrails is an open-source provenance management and scientific workflow system designed to support scientific discovery. It combines and substantially extends useful features of visualization and scientific workflow systems. Similar to visualization systems, VisTrails makes advanced scientific visualization techniques available to users allowing them to explore and compare different visual representations of their data; and similar to scientific workflow systems, VisTrails enables the composition of workflows that combine specialized libraries, distributed computing infrastructure, and Web services.\n","date":1299196800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1299196800,"objectID":"5daed8934f6ededecb5f8bf68b01e89f","permalink":"/siam2011.html","publishdate":"2011-03-04T00:00:00Z","relpermalink":"/siam2011.html","section":"post","summary":"A mini-symposium at the SIAM Conference on Computational Science \u0026amp; Engineering in Reno, NV on March 4, 2011.\nSummary As research grows increasingly dependent on computing, it becomes critical for our computational resources to be developed with the same rigor, open review and access as the results they support. In this minisymposium, we will discuss:\n sharing of scientific software, data and knowledge necessary for reproducible research unrestricted access to research outcomes and educational tools open source software developed by collaborative, meritocratic communities openly tested, validated and documented software as the basis for reliable scientific outcomes high standards of computational literacy in the education of mathematicians, scientists and engineers  MS148 - Part I of II The Challenge of Reproducible Research in the Computer Age (slides)","tags":null,"title":"Verifiable, reproducible research and computational science","type":"post"},{"authors":null,"categories":null,"content":"Michael Aivazis and I guest edited the March/April 2011 special issue of Computing in Science and Engineering on Python for Scientists and Engineers.\n","date":1298937600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1298937600,"objectID":"d9d836f73de4c1932bc1389d92a6d35b","permalink":"/cise2011.html","publishdate":"2011-03-01T00:00:00Z","relpermalink":"/cise2011.html","section":"post","summary":"Michael Aivazis and I guest edited the March/April 2011 special issue of Computing in Science and Engineering on Python for Scientists and Engineers.","tags":null,"title":"Python for Scientists and Engineers","type":"post"},{"authors":null,"categories":null,"content":" A one-day workshop on held at the Mathematical Sciences Research Institute (MSRI) in on June 25, 2010 in Berkeley, CA.\n 09:00-09:10 Welcome Jarrod Millman and William Stein 09:10-10:10 What to demand from a Scientific Computing Language \u0026ndash; Even if you don\u0026rsquo;t care about computing or languages - Peter Norvig (Google) 10:10-11:00 Cython: the best of both worlds - Robert Bradshaw (Google) 11:00-11:50 Python: an ecosystem for scientific computing - Fernando Perez (UC Berkeley) 12:00-14:00 LUNCH 14:00-14:50 Python in science and engineering education in India - Prabhu Ramachandran (IIT Bombay) 14:50-15:40 Sage: creating a viable open source alternative to Magma, Maple, Mathematica, and Matlab - William Stein (University of Washington) 15:40-16:10 BREAK 16:10-17:00 The foundation for mathematical and scientific computing - Jarrod Millman (UC Berkeley) 17:00-18:00 DISCUSSION  The workshop will be held in Simon\u0026rsquo;s auditorium at MSRI:\nSimon's auditorium Mathematical Science Research Institute 17 Gauss Way Berkeley, CA 94720  Abstracts Cython: the best of both worlds\nRobert Bradshaw\nCython is an extension to the Python language that allows explicit type declarations and is compiled directly to C. This addresses Python\u0026rsquo;s large overhead for numerical loops and the difficulty of efficiently making use of existing C and Fortran code, which Cython code can interact with natively. The Cython language combines the speed of C with the power and simplicity of the Python language.\nPython: an ecosystem for scientific computing\nFernando Perez\nAs the relationship between research and computing evolves, new tools are required that can not only treat numerical problems, but also allow us to solve a variety of problems involving large datasets in many formats, new algorithms and computational systems like databases or internet servers.\nI will discuss how Python provides a balance of clarity and flexibility, without sacrificing avenues for performance, to develop better computational research tools.\nPython in science and engineering education in India\nPrabhu Ramachandran\nThe National Mission on Education through ICT (NMEICT) is a one billion dollar initiative launched by the Ministry of Human Resources Development (MHRD), Government of India. It\u0026rsquo;s goal is to improve the quality of tertiary education in India. One component of the mission involves the spread of open source tools in collegiate education.\nIn May 2009, IIT Bombay proposed a project on Free Open source Software for Science and Engineering Education (FOSSEE) as part of this mission. The project is to run for three years. One of the thrust areas of FOSSEE is the propagation of the use of Python in science and engineering curricula. To this end, we have been conducting numerous workshops on Python for scientific computing, generating documentation, hosting conferences etc. The workshops are targeted at faculties of colleges, research scholars and students. In this talk, we discuss what we have achieved until now and highlight our future plans for the project. We also attempt to highlight what this will do for the Python community at large.\nSage: creating a viable open source alternative to Magma, Maple, Mathematica, and Matlab\nWilliam Stein\nSage is an open source mathematical software project that I started in 2005, which has had over 200 contributors, about 50 active developers, and receives funding from NSF, Google, Microsoft, and other organizations. The goal of the Sage project is to create a viable free open source alternative to Magma, Maple, Mathematica and MATLAB. I will describe why I started the Sage project, then give a status report about what Sage currently is. This paper is closely related to my talk.\nThe foundation for mathematical and scientific computing\nJarrod Millman\nWilliam Stein, Fernando Perez, and I are founding a non-profit foundation for mathematical and scientific research computing. Our purpose is to ensure unrestricted access to the best computational tools for research and education in mathematics, science, and engineering. Our aim is to do this primarily by fostering existing efforts and communities. The foundation will initially focus on Python, rather than other languages for scientific computing such as R or Scilab. Despite this initial focus on Python, the foundation\u0026rsquo;s mission will not be merely to promote the use of Python in science.\nAs research grows increasingly dependent on computing, it becomes critical for our computational resources to be developed with the same rigor, open review and access as the results they support. For this reason, we will actively promote:\n sharing of scientific software, data and knowledge necessary for reproducible research unrestricted access to research outcomes and educational tools open source software developed by collaborative, meritocratic communities academic recognition of computational developments on equal footing to the publication of results openly tested, validated and documented software as the basis for reliable scientific outcomes high standards of computational literacy in the education of mathematicians, scientists and engineers  ","date":1277424000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1277424000,"objectID":"fb4cc76d0a51a7a413dd7f74e2972dad","permalink":"/orcp2010.html","publishdate":"2010-06-25T00:00:00Z","relpermalink":"/orcp2010.html","section":"post","summary":"A one-day workshop on held at the Mathematical Sciences Research Institute (MSRI) in on June 25, 2010 in Berkeley, CA.\n 09:00-09:10 Welcome Jarrod Millman and William Stein 09:10-10:10 What to demand from a Scientific Computing Language \u0026ndash; Even if you don\u0026rsquo;t care about computing or languages - Peter Norvig (Google) 10:10-11:00 Cython: the best of both worlds - Robert Bradshaw (Google) 11:00-11:50 Python: an ecosystem for scientific computing - Fernando Perez (UC Berkeley) 12:00-14:00 LUNCH 14:00-14:50 Python in science and engineering education in India - Prabhu Ramachandran (IIT Bombay) 14:50-15:40 Sage: creating a viable open source alternative to Magma, Maple, Mathematica, and Matlab - William Stein (University of Washington) 15:40-16:10 BREAK 16:10-17:00 The foundation for mathematical and scientific computing - Jarrod Millman (UC Berkeley) 17:00-18:00 DISCUSSION  The workshop will be held in Simon\u0026rsquo;s auditorium at MSRI:","tags":null,"title":"Open Research Computing in Python","type":"post"}]